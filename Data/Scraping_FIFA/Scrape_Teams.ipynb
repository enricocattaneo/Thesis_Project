{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SCRAPE TEAM (on fifaindex.com)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from random import uniform\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import json\n",
    "from random import choice\n",
    "from urllib3.util import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import urllib3.exceptions\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_request(pageURL):\n",
    "    global errors\n",
    "    headers_list = [\n",
    "          {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "           \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "           \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "           \"Referer\": \"https://www.google.com/\",\n",
    "           \"DNT\": \"1\",\n",
    "           \"Connection\": \"keep-alive\",\n",
    "           \"Upgrade-Insecure-Requests\": \"1\"\n",
    "           },\n",
    "          {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\",\n",
    "               \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "               \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "               \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "               \"Referer\": \"https://www.google.com/\",\n",
    "               \"DNT\": \"1\",\n",
    "               \"Connection\": \"keep-alive\",\n",
    "               \"Upgrade-Insecure-Requests\": \"1\"\n",
    "           },\n",
    "          {\"Connection\": \"keep-alive\",\n",
    "               \"DNT\": \"1\",\n",
    "               \"Upgrade-Insecure-Requests\": \"1\",\n",
    "               \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "               \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "               \"Sec-Fetch-Site\": \"none\",\n",
    "               \"Sec-Fetch-Mode\": \"navigate\",\n",
    "               \"Sec-Fetch-Dest\": \"document\",\n",
    "               \"Referer\": \"https://www.google.com/\",\n",
    "               \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "               \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\"\n",
    "           },\n",
    "          {\"Connection\": \"keep-alive\",\n",
    "               \"Upgrade-Insecure-Requests\": \"1\",\n",
    "               \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36\",\n",
    "               \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
    "               \"Sec-Fetch-Site\": \"same-origin\",\n",
    "               \"Sec-Fetch-Mode\": \"navigate\",\n",
    "               \"Sec-Fetch-User\": \"?1\",\n",
    "               \"Sec-Fetch-Dest\": \"document\",\n",
    "               \"Referer\": \"https://www.google.com/\",\n",
    "               \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "               \"Accept-Language\": \"en-US,en;q=0.9\"\n",
    "           }]\n",
    "           \n",
    "    time.sleep(uniform(0, 2.25))\n",
    "    req = requests.Session()\n",
    "    headers = choice(headers_list)\n",
    "    retry = Retry(total=8, connect=8, backoff_factor=2)\n",
    "    req.mount('https://', HTTPAdapter(max_retries=retry))\n",
    "     \n",
    "    try:\n",
    "        html = req.get(pageURL, headers=headers, timeout=12)\n",
    "    except requests.packages.urllib3.exceptions.MaxRetryError:\n",
    "        errors.append('requests.packages.urllib3.exceptions.MaxRetryError')\n",
    "        html = requests.get('http://google.com/f')\n",
    "    except urllib3.exceptions.MaxRetryError:\n",
    "        errors.append('urllib3.exceptions.MaxRetryError')\n",
    "        html = requests.get('http://google.com/f')\n",
    "    except requests.ConnectionError:\n",
    "        errors.append('requests.ConnectionError')\n",
    "        html = requests.get('http://google.com/f')\n",
    "    except urllib3.exceptions.ConnectionError:\n",
    "        errors.append('urllib3.exceptions.ConnectionError')\n",
    "        html = requests.get('http://google.com/f')\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        errors.append('requests.exceptions.ConnectionError')\n",
    "        html = requests.get('http://google.com/f')\n",
    "    except Exception as ex:\n",
    "        errors.append(str(ex))\n",
    "        html = requests.get('http://google.com/f')\n",
    "          \n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get All Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_allpages(seasons, championship):\n",
    "    global all_pages\n",
    "    for j in seasons:\n",
    "        for k in championship:\n",
    "            Newpage_to_add = 'https://www.fifaindex.com/teams/' + j + '/?' + k + '&order=desc'\n",
    "               \n",
    "            all_pages.add(Newpage_to_add)\n",
    "    return all_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Teams' Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teamlinks(page_url): \n",
    "    global teams_links\n",
    "    right_ending = re.findall('\\/fifa.*\\/', page_url)[0]\n",
    "    html = make_request(pageURL = page_url)\n",
    "    bs = BeautifulSoup(html.text, 'lxml')\n",
    "    for link in bs.find_all('a', href=re.compile('^(/team/)')): \n",
    "        if 'href' in link.attrs:\n",
    "            if link.attrs['href'] not in teams_links: \n",
    "                teams_links.add(re.sub('\\/fifa.*\\/$', right_ending, link.attrs['href'])) \n",
    "    return teams_links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape Team's Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_team(website_page):\n",
    "    # Request\n",
    "    team_html = make_request(pageURL = website_page)\n",
    "    soup = BeautifulSoup(team_html.text, 'lxml')\n",
    "    # Team information \n",
    "    dd = {}\n",
    "    dd['TeamName'] = (re.sub(' FIFA.+', '', soup.h1.text).strip()) # team name\n",
    "    # Observation Date\n",
    "    for date in soup.select('.dropdown:nth-child(3) .dropdown-toggle'):\n",
    "        dd['ObservationDate'] = date.text.strip()\n",
    "    # Rival team\n",
    "    if soup.find('a', class_='link-team').text is not None:\n",
    "        dd['RivalTeam'] = soup.find('a', class_='link-team').text\n",
    "    # Team attributes\n",
    "    for i in range(2,5): \n",
    "        for info in soup.select('.list-group-item:nth-child(' + str(i) + ')'):\n",
    "            match = re.match(\"(\\D+)(\\d{1,2})\", info.text, re.I)\n",
    "            dd[match.group(1)] = match.group(2)\n",
    "    # Transfer budget\n",
    "    tranfer_budget = soup.find('span',class_ = 'data-currency-euro').text \n",
    "    dd['TransferBudget'] = int(re.sub(r'[.â‚¬]', '', tranfer_budget))\n",
    "    # Team Attributes + Players Roles \n",
    "    list1, list2 = [], []\n",
    "    for value in soup.select('.card-body p'):\n",
    "        match = re.sub('\\d', '', value.text)\n",
    "        list1.append(match.strip())\n",
    "    for i in range(1,3): # exception in 2010-2018 period\n",
    "        if list1[i] == 'Passing':\n",
    "            list1[i] = 'BuildupPassing'\n",
    "    if list1[1] == 'Width': # exception in 2019- period\n",
    "        list1[1] = 'DefensiveWidth'\n",
    "    for vv in soup.select('.card-body .float-right'):\n",
    "        list2.append(vv.text)\n",
    "    for i in range(len(list1)):\n",
    "        if re.search(list2[i], list1[i]):\n",
    "            dd[re.sub(list2[i], '', list1[i]).strip()] = list2[i]\n",
    "        else:\n",
    "            dd[list1[i]] = list2[i]\n",
    "    # Team Players + Loaned Players\n",
    "    players, loaned_players = [], []\n",
    "    for player in soup.select('td:nth-child(6) .link-player'):\n",
    "        players.append(player.text)\n",
    "    dd['TeamRoster'] = players\n",
    "    for loanedplayer in soup.select('td:nth-child(4) .link-player'):\n",
    "        loaned_players.append(loanedplayer.text)\n",
    "    dd['LoanedPlayers'] = loaned_players\n",
    "\n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Final Operations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "all_pages = set()\n",
    "teams_links = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Open_Create_file(path, seas, champ):\n",
    "    global all_pages\n",
    "    if os.path.isfile(path):\n",
    "        j_file = open(path)\n",
    "        all_teams_pages = json.load(j_file)\n",
    "        j_file.close()\n",
    "    else: \n",
    "        get_allpages(seasons=seas, championship=champ)\n",
    "        for page in tqdm_notebook(all_pages, total=len(all_pages)):\n",
    "            all_teams_pages = get_teamlinks(page)\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(list(all_teams_pages), f, ensure_ascii=False, indent=4)\n",
    "        f.close()\n",
    "    return all_teams_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_list(ALL_team_player_pages):\n",
    "    final_list = []\n",
    "    count = 0\n",
    "    for team_page in tqdm_notebook(ALL_team_player_pages, total=len(ALL_team_player_pages)): \n",
    "        try:\n",
    "            final_list.append(scrape_team('https://www.fifaindex.com' + team_page))\n",
    "        except ValueError:\n",
    "            count += 1\n",
    "            final_list.append({'ERROR': team_page})  \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ANNUAL DATA \n",
    "years = ['fifa10_6', 'fifa11_7','fifa12_8','fifa13_11','fifa14_12','fifa15_16','fifa16_19','fifa17_75','fifa18_175','fifa19_280','fifa20_358','fifa21_421','fifa22_487'] # If possible always 1st observation in September when the market is closed else August\n",
    "# Major Leagues\n",
    "leagues = ['league=31', 'league=13','league=16','league=19','league=53']\n",
    "# Minor Leagues\n",
    "minor_leagues = ['league=14', 'league=17', 'league=20', 'league=32', 'league=54']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR WEEKLY DATA \n",
    "weeks = {'fifa10_6', 'fifa11_7', 'fifa12_8', 'fifa12_9', 'fifa13_11', 'fifa14_12', 'fifa15_16'}\n",
    "for i in range(19,60): # FIFA16\n",
    "    weeks.add('fifa16_' + str(i))\n",
    "for j in range(74,144): # FIFA17\n",
    "    weeks.add('fifa17_' + str(j))\n",
    "for k in range(174, 246): # FIFA18\n",
    "    weeks.add('fifa18_' + str(k))\n",
    "for a in range(279, 344): # FIFA19\n",
    "    weeks.add('fifa19_' + str(a))\n",
    "for b in range(354,416): # FIFA20\n",
    "    weeks.add('fifa20_' + str(b))\n",
    "for c in range(420, 465): # FIFA21\n",
    "    weeks.add('fifa21_' + str(c))\n",
    "for d in range(487, 528): # FIFA22\n",
    "    weeks.add('fifa22_' + str(d))\n",
    "len(weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR UPDATE: just add new weeks\n",
    "new_weeks = ['fifa15_17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4f3d58c32b4388b89bf2a66891b174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_teams_pages = Open_Create_file(path='Dirty data/all_teams_15_new.json', seas=new_weeks, champ=minor_leagues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b48e8f8afb425fbea996a4cb428a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final = get_final_list(all_teams_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final) == len(all_teams_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final)\n",
    "df.to_csv(\"Dirty data/Teamdata_weekly_NEW.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
