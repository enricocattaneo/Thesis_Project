{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ORGANIZE DYNAMIC AND ODDS DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "# Change Pandas rows and columns' options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a nested dictionary into a flattened dictionary\n",
    "def flatten(d, parent_key='', sep='_'): \n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from a dataframe's column (which contains list objects) and organize it in a new dataframe\n",
    "def listcolumn_to_df(starting_df, column_toextract):\n",
    "    all_matches = []\n",
    "    for j in range(len(starting_df)):\n",
    "        match_FT = {}\n",
    "        single_match = eval(starting_df[column_toextract].iloc[j])\n",
    "        for i in range(len(single_match)):\n",
    "            if column_toextract in ['substitutions', 'lineup', 'bench', 'sidelined']:\n",
    "                match_FT[column_toextract[:4].upper() + \"pl{0}\".format(i+1)] = single_match[i]\n",
    "            else:\n",
    "                match_FT[column_toextract[:4].upper() + \"{0}\".format(i+1)] = single_match[i]\n",
    "        all_matches.append(flatten(match_FT))\n",
    "    df = pd.DataFrame(all_matches) \n",
    "    df.dropna(how = 'all', inplace = True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeps only bets from either a JSON file or a Python object that appear more than a certain treshold value (n_tokeep)\n",
    "def keep_n_mostcommon_odds(jsonfilepath_or_object, n_tokeep):\n",
    "    if isinstance(jsonfilepath_or_object, str):\n",
    "        f = open(jsonfilepath_or_object)\n",
    "        odds_data = json.load(f)\n",
    "        f.close()\n",
    "    elif isinstance(jsonfilepath_or_object, object):\n",
    "        odds_data = jsonfilepath_or_object\n",
    "\n",
    "    feat = [key for fix in odds_data for key in fix.keys()]\n",
    "    feat_count = collections.Counter(feat).most_common()\n",
    "    frequent_feats = {x[0] for x in feat_count if x[1] > n_tokeep}\n",
    "    new_odds = [{k: fix[k] for k in frequent_feats if k in fix} for fix in odds_data]\n",
    "    \n",
    "    check = {key for i in new_odds for key in i.keys()}\n",
    "    if check == frequent_feats:\n",
    "        print('Check for correct keys: OK')\n",
    "        print('Features with at least ', n_tokeep, 'observations: ', len(frequent_feats))\n",
    "    else: \n",
    "        print('Check for correct keys: ERROR') \n",
    "    return new_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns to the Dataframe for both the captain of team1 and team2, and drop all other captain variables in the Df \n",
    "def handling_captains(initial_df):\n",
    "    captains = {}\n",
    "    cap1_temp = {}\n",
    "    cap2_temp = {}\n",
    "    for ob in range(len(initial_df)):\n",
    "        match_caps = []\n",
    "        for num, col in enumerate(initial_df.filter(regex='captain$').columns):\n",
    "            if initial_df[col].iloc[ob] is True:\n",
    "                match_caps.append(num+1)\n",
    "        captains[initial_df.index[ob]] = match_caps\n",
    "    \n",
    "    for key, value in captains.items():\n",
    "        if len(value) == 2:\n",
    "            cap1_temp[key] = value[0]\n",
    "            cap2_temp[key] = value[1]\n",
    "        else:\n",
    "            cap1_temp[key] = cap2_temp[key] = np.nan\n",
    "    \n",
    "    initial_df = initial_df.merge(pd.Series(cap1_temp).rename('captain_team1'), left_index=True, right_index=True).merge(\n",
    "        pd.Series(cap2_temp).rename('captain_team2'), left_index=True, right_index=True)\n",
    "    initial_df.drop(initial_df.filter(regex='_captain$').columns, axis = 1, inplace=True)\n",
    "    return initial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ALL DYNAMIC DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Starting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import leagues_more from csv\n",
    "leagues_more = pd.read_csv('Input Data/leagues_more.csv', low_memory = False)\n",
    "leagues_more.set_index('id', inplace = True)\n",
    "leagues_more.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lineup Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lineup Dataframe\n",
    "lineups_df = listcolumn_to_df(leagues_more, 'lineup')\n",
    "# Create new columns \n",
    "lineups_df['team_id_TEAM1'] = lineups_df['LINEpl1_team_id']\n",
    "lineups_df['team_id_TEAM2'] = lineups_df['LINEpl17_team_id']\n",
    "lineups_df['Fix_ID'] = lineups_df['LINEpl1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "lineups_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "lineups_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain values \n",
    "lineups_df = lineups_df.loc[:,~lineups_df.columns.str.endswith('posx')]\n",
    "lineups_df = lineups_df.loc[:,~lineups_df.columns.str.endswith('posy')]\n",
    "lineups_df = lineups_df.loc[:,~lineups_df.columns.str.endswith('number')]\n",
    "lineups_df.drop(lineups_df.filter(regex='_type$').columns, axis = 1, inplace=True)\n",
    "lineups_df.drop(lineups_df.filter(regex='_team_id$').columns, axis = 1, inplace=True)\n",
    "lineups_df.drop(lineups_df.filter(regex='formation_position$').columns, axis = 1, inplace=True)\n",
    "lineups_df.drop(lineups_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "# Call handling_captains() function\n",
    "lineups_df = handling_captains(lineups_df)\n",
    "# Transform all floats in integers\n",
    "m = lineups_df.select_dtypes(np.number)\n",
    "lineups_df[m.columns]= m.round().astype('Int64')\n",
    "# Transform rating from obj to float\n",
    "lineups_df[lineups_df.filter(regex='_rating$').columns] = lineups_df.filter(regex='_rating$').astype('float64')\n",
    "# Change the order of lineups_df columns\n",
    "cols = lineups_df.columns.tolist()\n",
    "cols = cols[-4:] + cols[:-4]\n",
    "lineups_df = lineups_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lineups_df.shape)\n",
    "lineups_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Subs Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subs Dataframe\n",
    "subs_df = listcolumn_to_df(leagues_more, 'substitutions')\n",
    "# Create new columns\n",
    "subs_df['Fix_ID'] = subs_df['SUBSpl1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "subs_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "subs_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain patterns \n",
    "subs_df.drop(subs_df.filter(regex='SUBSpl\\d{1,2}_id$').columns, axis = 1, inplace=True)\n",
    "subs_df.drop(subs_df.filter(regex='_type$').columns, axis = 1, inplace=True)\n",
    "subs_df.drop(subs_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "subs_df.drop(subs_df.filter(regex='_extra_minute$').columns, axis = 1, inplace=True)\n",
    "# Tranform injured columns to binary variable\n",
    "for i in subs_df.filter(regex='_injuried$').columns:\n",
    "    subs_df[i] = subs_df[i].map({True: 1, None: 0, False: 0})\n",
    "# Transform all floats in integers\n",
    "m1 = subs_df.select_dtypes(np.number)\n",
    "subs_df[m1.columns]= m1.round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subs_df.shape)\n",
    "subs_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bench Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bench Dataframe\n",
    "bench_df = listcolumn_to_df(leagues_more, 'bench')\n",
    "# Create new columns \n",
    "bench_df['Fix_ID'] = bench_df['BENCpl1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "bench_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "bench_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain values \n",
    "bench_df = bench_df.loc[:,~bench_df.columns.str.endswith('posx')]\n",
    "bench_df = bench_df.loc[:,~bench_df.columns.str.endswith('posy')]\n",
    "bench_df = bench_df.loc[:,~bench_df.columns.str.endswith('number')]\n",
    "bench_df = bench_df.loc[:,~bench_df.columns.str.endswith('captain')]\n",
    "bench_df.drop(bench_df.filter(regex='_type$').columns, axis = 1, inplace=True)\n",
    "bench_df.drop(bench_df.filter(regex='formation_position$').columns, axis = 1, inplace=True)\n",
    "bench_df.drop(bench_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "# Transform all floats in integers\n",
    "m2 = bench_df.select_dtypes(np.number)\n",
    "bench_df[m2.columns]= m2.round().astype('Int64')\n",
    "# Transform rating from obj to float\n",
    "bench_df[bench_df.filter(regex='_rating$').columns] = bench_df.filter(regex='_rating$').astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bench_df.shape)\n",
    "bench_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sidelined Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side Dataframe\n",
    "side_df = listcolumn_to_df(leagues_more, 'sidelined')\n",
    "# Create new columns \n",
    "side_df['Fix_ID'] = side_df['SIDEpl1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "side_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "side_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain values \n",
    "side_df.drop(side_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "# Transform all floats in integers\n",
    "m3 = side_df.select_dtypes(np.number)\n",
    "side_df[m3.columns]= m3.round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(side_df.shape)\n",
    "side_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Corners Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corners Dataframe\n",
    "corners_df = listcolumn_to_df(leagues_more, 'corners')\n",
    "# Create new columns \n",
    "corners_df['Fix_ID'] = corners_df['CORN1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "corners_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "corners_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain pattern\n",
    "corners_df.drop(corners_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "corners_df.drop(corners_df.filter(regex='_comment$').columns, axis = 1, inplace=True)\n",
    "corners_df.drop(corners_df.filter(regex='_extra_minute$').columns, axis = 1, inplace=True)\n",
    "corners_df.drop(corners_df.filter(regex='CORN\\d{1,2}_id$').columns, axis = 1, inplace=True)\n",
    "# Transform all floats in integers\n",
    "m4 = corners_df.select_dtypes(np.number)\n",
    "corners_df[m4.columns]= m4.round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corners_df.shape)\n",
    "corners_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cards Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cards Dataframe\n",
    "cards_df = listcolumn_to_df(leagues_more, 'cards')\n",
    "# Create new columns \n",
    "cards_df['Fix_ID'] = cards_df['CARD1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "cards_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "cards_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain pattern\n",
    "cards_df.drop(cards_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "cards_df.drop(cards_df.filter(regex='_extra_minute$').columns, axis = 1, inplace=True)\n",
    "cards_df.drop(cards_df.filter(regex='CARD\\d{1,2}_id$').columns, axis = 1, inplace=True)\n",
    "# Tranform type columns to shorter codes\n",
    "for i in cards_df.filter(regex='_type$').columns:\n",
    "    cards_df[i] = cards_df[i].map({'yellowcard': 'Y', 'redcard': 'R', 'yellowred': 'YR'})\n",
    "# Transform all floats in integers\n",
    "m5 = cards_df.select_dtypes(np.number)\n",
    "cards_df[m5.columns]= m5.round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cards_df.shape)\n",
    "cards_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goals Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create goals Dataframe\n",
    "goals_df = listcolumn_to_df(leagues_more, 'goals')\n",
    "# Create new columns \n",
    "goals_df['Fix_ID'] = goals_df['GOAL1_fixture_id'].astype('int')\n",
    "# Set Fixture_id as index\n",
    "goals_df.set_index('Fix_ID', inplace=True)\n",
    "# Drop all columns that have only NAs \n",
    "goals_df.dropna(axis=1, how='all', inplace=True)\n",
    "# Drop all columns which name match certain pattern\n",
    "goals_df.drop(goals_df.filter(regex='GOAL\\d{1,2}_id$').columns, axis = 1, inplace=True)#\n",
    "goals_df.drop(goals_df.filter(regex='_extra_minute$').columns, axis = 1, inplace=True)\n",
    "goals_df.drop(goals_df.filter(regex='_fixture_id$').columns, axis = 1, inplace=True)\n",
    "goals_df.drop(goals_df.filter(regex='_reason$').columns, axis = 1, inplace=True)\n",
    "# Tranform type columns to shorter codes\n",
    "for i in goals_df.filter(regex='_type$').columns:\n",
    "    goals_df[i] = goals_df[i].map({'goal': 'G', 'penalty': 'P', 'own-goal': 'O-G'})\n",
    "# Transform all floats in integers\n",
    "m6 = goals_df.select_dtypes(np.number)\n",
    "goals_df[m6.columns]= m6.round().astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(goals_df.shape)\n",
    "goals_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ODDS DATA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_leagues_odds = keep_n_mostcommon_odds('Input Data/final_leagues_odds.json', 3500)\n",
    "only_cups_odds = keep_n_mostcommon_odds('Input Data/final_cups_odds.json', 2000)\n",
    "\n",
    "with open('Input Data/final_leagues_odds.json') as f: odds_data_leagues = json.load(f)\n",
    "f.close()\n",
    "with open('Input Data/final_cups_odds.json') as g: odds_data_cups = json.load(g)\n",
    "g.close()\n",
    "\n",
    "complete_odds = odds_data_cups + odds_data_leagues\n",
    "merged_odds = keep_n_mostcommon_odds(complete_odds, 5000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Leagues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues_odds_df = pd.DataFrame(only_leagues_odds)\n",
    "leagues_odds_df.set_index('id', inplace=True)\n",
    "leagues_odds_df.dropna(axis=0, how='all', inplace=True)\n",
    "leagues_odds_df.dropna(axis=1, how='all', inplace=True)\n",
    "leagues_odds_df.drop(leagues_odds_df.filter(regex='^ToQualify_').columns, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(leagues_odds_df.shape)\n",
    "leagues_odds_df.tail()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
